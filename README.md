# Deep Learning

This module addresses the fundamental concepts and advanced methodologies of deep learning and relates them to real-world problems in a variety of domains. The aim is to provide an overview of different approaches, both classical and emerging. The module will equip you with the necessary knowledge and skills to work in the field of deep learning and to contribute to ongoing research in the area.

# Coursework

Coursework 1: Design, train and optimise a custom deep learning model for classifying a specially selected subset of Imagenet. Termed NaturalImageNet, it is made up of a hand selected subset of the famous ImageNet dataset. The dataset contains 20 classes, all animals from the natural world. (100%)

Coursework 2: Implement two commonly used generative models: A Variational Autoencoder (VAE) and A Deep Convolutional Generative Adversarial Network (DCGAN). (99%)


# Notes 

| Week | Topics                                | Notes                                        | Lecture Notes                                                            | Tutorials                      | Papers                |
| ---- | ------------------------------------- | -------------------------------------------- | ------------------------------------------------------------------------ | ------------------------------ | --------------------- |
| 2    | Curse of Dimensionality/CNN           | [[Week 2]]                                   | [[N01_Convolutions.pdf]]                                                 | [[Tutorial 1.pdf]]             |                       |
| 3    | Equivariance and Invariance           | [[Week 3 - 02]]                              | [[N02_equivariance.pdf]]                                                 | [[Tutorial 3.pdf]]             |                       |
|      | LeNet                                 | [[Week 3 - 03]]                              | [[N03_LeNet.pdf]]                                                        |                                | [[LeNet_paper.pdf]]   |
|      | AlexNet                               | [[Week 3 - 04]]                              | [[N04_AlexNet.pdf]]                                                      |                                | [[AlexNet_paper.pdf]] |
|      | VGG                                   | [[Week 3 - 05]]                              | [[N05_VGG notes.pdf]]                                                    |                                | [[VGG.pdf]]           |
| 4    | Inception                             | [[Week 4 - 06]]                              | [[N06_Inception.pdf]]                                                    | [[T04_covariateShift.pdf.pdf]] | [[Inception.pdf]]     |
|      | Batch Normalisation                   | [[Week 4 - 07]]                              | [[N07_BatchNorm.pdf.pdf]]                                                |                                | [[ResNet.pdf]]        |
|      | ResNet                                | [[Week 4 - 08]]                              | [[N08_ResNet.pdf.pdf]]                                                   |                                | [[BatchNorm.pdf]]     |
|      | Activation Functions                  | [[Week 4 - 09]]                              | [[N09_activations.pdf]]                                                  |                                |                       |
|      | Loss functions                        | [[Week 4 - 10]]                              | [[N10_losses.pdf.pdf]]                                                   |                                |                       |
|      | Data Augmentation                     | [[Week 4 - 11]]                              | [[N11_augmentation.pdf.pdf]]                                             |                                |                       |
|      | U-Net Architecture                    | [[Week 4 - 12]]                              |                                                                     |                                |                       |
| 5    | Intro to Generative Models            | [[Week 5 - Generative Models]]               | [[N15_generative_models_intro_slides.pdf.pdf]]                           | [[T06_VAEsandGANs.pdf]]        |                       |
|      | Variational Autoencoder               | [[Week 5 - VAE Basics]]                      | [[N16_VAE.pdf.pdf]] [[N16a_generative_models_vae_basics_slides.pdf.pdf]] |                                | [[VAEs.pdf]]          |
|      | Generative Adversarial Models         | [[Week 5 - GANs]]                            | [[N17_GAN.pdf.pdf]] [[N17a_generative_models_gan_basics_slides.pdf.pdf]] |                                | [[GANs.pdf]]          |
|      | Advances and Applications             | [[Week 5 - Advances and Applications]]       | [[N17b_generative_models_advance_slides.pdf.pdf]]                        |                                |                       |
| 6    | RNN                                   | [[Week 6 - RNNs]]                            | [[N18_RNN.pdf]] [[N18a_recurrent_neural_networks_basics_slides.pdf.pdf]] |                                |                       |
|      | RNN Applications                      | [[Week 6 - RNNs Applications]]               | [[N19_recurrent_neural_networks_applications_slides.pdf.pdf]]            |                                |                       |
|      | Attention & Transformers              | [[Week 6 - Attention & Transformers Basics]] | [[N20_attention.pdf]] [[N20a_attention_basics_slides.pdf.pdf]]           |                                |                       |
|      | Attention & Transformers Applications | [[Week 6 - Advances and Applications]]                                             | [[N21_attention_advance_slides.pdf.pdf]]                                 |                                |                       |



